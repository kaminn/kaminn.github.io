<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CMU 15-445 Project 1 Buffer Pool</title>
    <url>/2022/05/02/CMU-15-445-Project-1-Buffer-Pool/</url>
    <content><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>CMU 15-445 Fall 2021的课程期间需要完成一个基于磁盘的数据库Bustub，而这是其第一个Project（跳过了Project 0），其目标是构建一个Buffer Pool，Buffer Pool负责将物理页面从内存和磁盘之间进行换进换出。DBMS中执行引擎需要用到某页时，并非之间从磁盘中读取，而是从Buffer Pool中获取该页，由Buffer Pool负责页面的获取、淘汰。</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/image-20220502223257589.png" alt="磁盘、Buffer Pool和执行引擎"></p>
<span id="more"></span>

<p>Buffer Pool内部维护一个固定大小的frame数组，记录Buffer Pool中缓存的页，还有一个page table用于记录page id与frame之间的关系。具体的Buffer Pool还需要通过具体的策略控制页面的淘汰，记录每个页面的使用情况以实现线程安全的控制、数据的安全等。</p>
<p>虽然看上去Buffer Pool的实现有些复杂，但是Project已经帮我们拆解好了任务，我们可以通过进行页面淘汰策略和页的管理两个方面的工作来实现Buffer Pool，具体到Project中分为以下三个任务:</p>
<ul>
<li><p><strong>LRU Replacement Policy</strong></p>
</li>
<li><p><strong>Buffer Pool Manager Instance</strong></p>
</li>
<li><p><strong>Parallel Buffer Pool Manager</strong></p>
</li>
</ul>
<p>因为我学习的时候其实时看的2019年的课程视频，所以我还额外完成了19年的Project1中有的<code>Clock Replacement Policy</code></p>
<h1 id="Clock-Replacement-Policy"><a href="#Clock-Replacement-Policy" class="headerlink" title="Clock Replacement Policy"></a>Clock Replacement Policy</h1><p>Clock Replacement Policy是一种近似LRU的淘汰策略，它通过将页组织成一个环进行扫描，每个页上有一个reference bit用于记录该页是否被访问过，如果页面被访问则reference bit设为1，否则为0。</p>
<p>每次扫描时，如果页面的reference bit为1，说明页面自上次扫描之后有过访问，则仅将reference bit设为0不进行淘汰；如果reference bit设为0，说明页面自上次扫描之后还没有被访问过，就可以将页面进行淘汰了。</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/image-20220502232335875.png" alt="Clock Replacement Policy描述"></p>
<p>我们需要实现一个<code>ClockReplacer</code>，代码框架已经给出，需要按照给定的框架实现<code>Replacer</code>接口:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 调用Victim方法表示需要淘汰一个Replacer中最近最少使用的frame，如果成功淘汰了这样的frame，将其frame id存储到frame_id中并返回true，</span></span><br><span class="line"><span class="comment"> * 否则返回false</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Victim</span><span class="params">(<span class="type">frame_id_t</span> *frame_id)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 调用Pin方法表示Buffer Pool需要使用该frame，将该frame从Replacer中删除</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Pin</span><span class="params">(<span class="type">frame_id_t</span> frame_id)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 调用Unpin方法表示该frame没有线程在使用了，需要加入Replacer等待淘汰</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Unpin</span><span class="params">(<span class="type">frame_id_t</span> frame_id)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 返回Replacer的大小</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">size_t</span> <span class="title">Size</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>

<p><code>ClockReplacer</code>的实现比较简单，需要注意记录<code>clock_hand</code>也就是当前扫描的clock位置、clock是否存在以及是否被访问，然后根据算法描述去更新这些信息就好了，注意加锁保证线程安全。</p>
<h1 id="LRU-Replacement-Policy"><a href="#LRU-Replacement-Policy" class="headerlink" title="LRU Replacement Policy"></a>LRU Replacement Policy</h1><p>LRU应该很熟悉了，最近最少使用淘汰，可以看下<a href="https://leetcode-cn.com/problems/lru-cache/">146. LRU 缓存 - LeetCode</a>。在Project中，我们需要实现一个<code>LRUReplacer</code>，还是按照上面的<code>Replacer</code>接口，这个接口和LeetCode上的get、put等还不太一样。</p>
<p>这里的<code>LRUReplacer</code>中记录的是可以被淘汰的页，而不是全部的页。Pin的过程是从<code>LRUReplacer</code>中删除该页面，这样该页面就不会被淘汰了。Unpin则是在<code>LRUReplacer</code>中加入该页面，这样该页面就可能被淘汰。</p>
<p><code>LRUReplacer</code>我们还是通过hashmap+双向链表的形式来实现，链表中存储<code>frame_id</code>，每次将最近访问过的<code>frame_id</code>添加到链表头部，每次淘汰<code>frame_id</code>从链表尾部开始淘汰。hashmap中存储<code>frame_id</code>以及<code>frame_id</code>在链表中的位置，用于实现以O(1)时间复杂度获取到<code>frame_id</code>。具体的实现如下:</p>
<h2 id="bool-Victim-frame-id-t-frame-id"><a href="#bool-Victim-frame-id-t-frame-id" class="headerlink" title="bool Victim(frame_id_t *frame_id)"></a>bool Victim(frame_id_t *frame_id)</h2><p>只要链表不为空，则从链表尾部淘汰一个<code>frame_id</code>返回，删除hashmap中对应的<code>frame_id</code>，并返回true，否则返回false。</p>
<h2 id="void-Pin-frame-id-t-frame-id"><a href="#void-Pin-frame-id-t-frame-id" class="headerlink" title="void Pin(frame_id_t frame_id)"></a>void Pin(frame_id_t frame_id)</h2><p>在hashmap中找到<code>frame_id</code>，直接将该frame从hashmap和链表中都删除。</p>
<h2 id="void-Unpin-frame-id-t-frame-id"><a href="#void-Unpin-frame-id-t-frame-id" class="headerlink" title="void Unpin(frame_id_t frame_id)"></a>void Unpin(frame_id_t frame_id)</h2><p>当<code>frame_id</code>不在hashmap中且链表还未满时，把<code>frame_id</code>插入链表头部，hashmap记录<code>frame_id</code>在链表中的位置。</p>
<h2 id="size-t-Size"><a href="#size-t-Size" class="headerlink" title="size_t Size()"></a>size_t Size()</h2><p>直接返回链表的size。</p>
<p>以上的实现也要注意加锁保证线程安全。</p>
<h1 id="Buffer-Pool-Manager-Instance"><a href="#Buffer-Pool-Manager-Instance" class="headerlink" title="Buffer Pool Manager Instance"></a>Buffer Pool Manager Instance</h1><p><code>BufferPoolManagerInstance</code>即是管理Buffer Pool的实体，负责从<code>DiskManager</code>获取页面并将它们存储在内存中。 <code>BufferPoolManagerInstance</code>也可以将脏页写回磁盘以持久化数据变更。</p>
<p>在内存中，数据库页总是以<code>Page</code>对象来表示，在系统的整个生命周期中，相同的<code>Page</code>对象可能包含不同的物理页面，<code>Page</code>对象中我们需要关心的属性有:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** page对象实际存储的数据 */</span></span><br><span class="line"><span class="type">char</span> data_[PAGE_SIZE]&#123;&#125;;</span><br><span class="line"><span class="comment">/** page id */</span></span><br><span class="line"><span class="type">page_id_t</span> page_id_ = INVALID_PAGE_ID;</span><br><span class="line"><span class="comment">/** 表示page被多少线程使用，引用计数*/</span></span><br><span class="line"><span class="type">int</span> pin_count_ = <span class="number">0</span>;</span><br><span class="line"><span class="comment">/** 该page是否为脏页 */</span></span><br><span class="line"><span class="type">bool</span> is_dirty_ = <span class="literal">false</span>;</span><br></pre></td></tr></table></figure>

<p><code>BufferPoolManagerInstance</code>中我们需要关心的属性有:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** page数组基地址，pages_+frame_id就可以定位到一个page对象 */</span></span><br><span class="line">Page *pages_;</span><br><span class="line"><span class="comment">/** page table，记录page_id与frame_id之间的映射关系 */</span></span><br><span class="line">std::unordered_map&lt;<span class="type">page_id_t</span>, <span class="type">frame_id_t</span>&gt; page_table_;</span><br><span class="line"><span class="comment">/** 负责淘汰页面，这里我们都使用LRUReplacer */</span></span><br><span class="line">Replacer *replacer_;</span><br><span class="line"><span class="comment">/** 空闲frame_id列表 */</span></span><br><span class="line">std::list&lt;<span class="type">frame_id_t</span>&gt; free_list_;</span><br></pre></td></tr></table></figure>

<p><code>BufferPoolManagerInstance</code>中我们需要实现的接口有:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 从Buffer Pool中获取一个页面</span></span><br><span class="line"><span class="comment">   * @param page_id 需要获取的页的page id</span></span><br><span class="line"><span class="comment">   * @return 获取到的页面</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function">Page *<span class="title">FetchPgImp</span><span class="params">(<span class="type">page_id_t</span> page_id)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 从Buffer Pool中unpin一个页面</span></span><br><span class="line"><span class="comment">   * @param page_id 需要unpin的page id</span></span><br><span class="line"><span class="comment">   * @param is_dirty 是否需要标记该页为脏页</span></span><br><span class="line"><span class="comment">   * @return 如果该页面的pin count在调用前已经小于等于0了就返回false，否则返回true</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">UnpinPgImp</span><span class="params">(<span class="type">page_id_t</span> page_id, <span class="type">bool</span> is_dirty)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 将Buffer Pool中的指定页面写回磁盘</span></span><br><span class="line"><span class="comment">   * @param page_id id 需要写回的page id，不能是INVALID_PAGE_ID</span></span><br><span class="line"><span class="comment">   * @return 如果页面在page table中不存在则返回false，否则返回true</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">FlushPgImp</span><span class="params">(<span class="type">page_id_t</span> page_id)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 创建一个新的页面</span></span><br><span class="line"><span class="comment">   * @param[out] page_id 新页面的page id写入这个参数</span></span><br><span class="line"><span class="comment">   * @return 创建成功返回新创建的页的指针，否则返回null</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function">Page *<span class="title">NewPgImp</span><span class="params">(<span class="type">page_id_t</span> *page_id)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 从Buffer Pool中删除一个页</span></span><br><span class="line"><span class="comment">   * @param page_id 待删除的页的page id</span></span><br><span class="line"><span class="comment">   * @return 删除成功返回true，失败返回false</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">DeletePgImp</span><span class="params">(<span class="type">page_id_t</span> page_id)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 把Buffer Pool中缓存的所有页面都写回磁盘</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">FlushAllPgsImp</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>

<p>Buffer Pool、Replacer和Disk Manager的交互逻辑如下:</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/buffer%20pool.png" alt="buffer pool"></p>
<p>Replacer类似于一个页面回收站，维护了没有线程使用的可以被清除的frame的<code>frame_id</code>，Buffer Pool每次使用完一个页面时调用<code>UnpinPgImp</code>将页面放入回收站，在需要获取页面时可以从回收站获取可以被复用的frame的<code>frame_id</code>。Buffer Pool从磁盘读取页面数据通过调用Disk Manager的<code>ReadPage</code>方法实现，Buffer Pool将内存页面数据写回磁盘通过调用Disk Manager的<code>WritePage</code>方法实现。</p>
<p>frame在Buffer Pool和Replacer之间流转，一共有三种状态，分别是free、pinned和unpinned，frame的状态流转如下:</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/frame%20status.png" alt="frame status"></p>
<p>具体来讲一讲每个接口的实现逻辑和需要注意的细节:</p>
<h2 id="Page-BufferPoolManagerInstance-NewPgImp-page-id-t-page-id"><a href="#Page-BufferPoolManagerInstance-NewPgImp-page-id-t-page-id" class="headerlink" title="Page *BufferPoolManagerInstance::NewPgImp(page_id_t *page_id)"></a>Page *BufferPoolManagerInstance::NewPgImp(page_id_t *page_id)</h2><p>给出的代码中已有详细的逻辑注释，方法执行逻辑流程如下:</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/new%20page.png" alt="new page"></p>
<p>需要注意的几个点是:</p>
<ul>
<li>先尝试从<code>free_list_</code>中获取空闲的frame，如果没有空闲的frame再尝试从<code>Replacer</code>获取一个淘汰的frame。</li>
<li>从<code>Replacer</code>中获取的淘汰的frame，一定要检查是否为脏页，如果为脏页需要先把先前的数据写回磁盘，以免脏页数据丢失。</li>
<li>从<code>Replacer</code>中获取的淘汰的frame，需要从<code>page_table_</code>中删除这个frame之前的<code>page_id_</code>与<code>frame_id</code>的映射。后面再用新的<code>page_id</code>映射<code>frame_id</code>。</li>
</ul>
<h2 id="Page-BufferPoolManagerInstance-FetchPgImp-page-id-t-page-id"><a href="#Page-BufferPoolManagerInstance-FetchPgImp-page-id-t-page-id" class="headerlink" title="Page *BufferPoolManagerInstance::FetchPgImp(page_id_t page_id)"></a>Page *BufferPoolManagerInstance::FetchPgImp(page_id_t page_id)</h2><p>请求指定<code>page_id</code>的内容，返回<code>page</code>指针，同样在给出的代码框架中已有详细的逻辑注释了，逻辑流程如下:</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/fetch%20page.png" alt="fetch page"></p>
<p>需要注意的点:</p>
<ul>
<li>如果<code>page_table_</code>中能找到对应的<code>page_id</code>，则可以不用读磁盘，直接返回对应的<code>page</code>指针。</li>
<li>如果<code>page_table_</code>中能找到对应的<code>page_id</code>，返回对应<code>page</code>指针之前，需要调用<code>replacer_</code>的<code>Pin</code>方法把对应的frame从回收站拿出来，<code>pin_count_</code>++。</li>
<li>更新<code>page</code>的metadata时，记得pin_count_++，表示线程正在使用这个页。</li>
</ul>
<h2 id="bool-BufferPoolManagerInstance-FlushPgImp-page-id-t-page-id"><a href="#bool-BufferPoolManagerInstance-FlushPgImp-page-id-t-page-id" class="headerlink" title="bool BufferPoolManagerInstance::FlushPgImp(page_id_t page_id)"></a>bool BufferPoolManagerInstance::FlushPgImp(page_id_t page_id)</h2><p><code>FlushPgImp</code>主要操作就是调用<code>disk_manager_</code>的<code>WritePage</code>方法将页的内容写回磁盘，逻辑比较简单，只要<code>page_id</code>不等于<code>INVALID_PAGE_ID</code>即-1，且<code>page_table_</code>中存在对应<code>page_id</code>，就将页内容写回磁盘，顺便将页的<code>is_dirty_</code>置为false。</p>
<h2 id="void-BufferPoolManagerInstance-FlushAllPgsImp"><a href="#void-BufferPoolManagerInstance-FlushAllPgsImp" class="headerlink" title="void BufferPoolManagerInstance::FlushAllPgsImp()"></a>void BufferPoolManagerInstance::FlushAllPgsImp()</h2><p>这个接口的实现也比较简单，就是遍历<code>page_table_</code>，将里面的页的内容全部写回到磁盘，顺便将页的<code>is_dirty_</code>置为false。</p>
<h2 id="bool-BufferPoolManagerInstance-DeletePgImp-page-id-t-page-id"><a href="#bool-BufferPoolManagerInstance-DeletePgImp-page-id-t-page-id" class="headerlink" title="bool BufferPoolManagerInstance::DeletePgImp(page_id_t page_id)"></a>bool BufferPoolManagerInstance::DeletePgImp(page_id_t page_id)</h2><p>这个接口可以直接删除Buffer Pool中的一个页，不用等<code>replacer_</code>去淘汰这个页。</p>
<p>具体的逻辑流程如下:</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/delete%20page.png" alt="delete page"></p>
<p>需要注意的点:</p>
<ul>
<li>只有<code>pin_count_</code>不为0时才返回false，其余情况都是返回true，<code>page_table_</code>中找不到<code>page_id</code>时也返回true，这个注释里有说。</li>
<li>这里是直接删除页面，所以不用再调用<code>replacer_</code>的<code>Unpin</code>方法把frame加入到回收站再等待淘汰，删除页面后的<code>frame_id</code>直接加入<code>free_list_</code>。</li>
</ul>
<h2 id="bool-BufferPoolManagerInstance-UnpinPgImp-page-id-t-page-id-bool-is-dirty"><a href="#bool-BufferPoolManagerInstance-UnpinPgImp-page-id-t-page-id-bool-is-dirty" class="headerlink" title="bool BufferPoolManagerInstance::UnpinPgImp(page_id_t page_id, bool is_dirty)"></a>bool BufferPoolManagerInstance::UnpinPgImp(page_id_t page_id, bool is_dirty)</h2><p>这个接口代码中没有给出太多的注释，不过经过上面的状态流转分析以及数据流分析等，这个方法的逻辑应该也比较清楚，具体的逻辑流程如下:</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/unpin%20page.png" alt="unpin page"></p>
<p>需要注意的点:</p>
<ul>
<li>只有调用时<code>pin_count_</code>已经小于等于0才返回false，其余情况都是返回true，<code>page_table_</code>中找不到<code>page_id</code>时也返回true，这个注释里有说。</li>
<li>不能直接将<code>page</code>的<code>is_dirty_</code>属性直接更新成参数<code>is_dirty</code>的值，因为可能出现<code>page</code>本身已经是脏页但是<code>is_dirty</code>给的是false，就有可能丢失数据。</li>
<li>只有<code>pin_count_</code>-1后为0时，才需要调用<code>replacer_</code>的<code>Unpin</code>方法。</li>
</ul>
<p>所有的接口都要记得加锁来保证线程安全。</p>
<h1 id="Parallel-Buffer-Pool-Manager"><a href="#Parallel-Buffer-Pool-Manager" class="headerlink" title="Parallel Buffer Pool Manager"></a>Parallel Buffer Pool Manager</h1><p>这是一个并行Buffer Pool管理器，内部管理着多个<code>BufferPoolManagerInstance</code>，对外暴露和<code>BufferPoolManagerInstance</code>同样的接口（它们都实现了<code>BufferPoolManager</code>接口）。</p>
<p><code>ParallelBufferPoolManager</code>内部维护了几个属性:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// BufferPoolManagerInstance实例数</span></span><br><span class="line"><span class="type">size_t</span> num_instances_;</span><br><span class="line"><span class="comment">// 下一个轮询的BufferPoolManagerInstance实例的index，NewPgImp接口有用到</span></span><br><span class="line"><span class="type">size_t</span> next_instance_index_;</span><br><span class="line"><span class="comment">// 每个实例的大小</span></span><br><span class="line"><span class="type">size_t</span> pool_size_;</span><br><span class="line"><span class="comment">// 每个实例的指针</span></span><br><span class="line">std::vector&lt;BufferPoolManager *&gt; instances_;</span><br></pre></td></tr></table></figure>

<p><code>ParallelBufferPoolManager</code>会将不同的<code>page_id</code>映射到不同的<code>BufferPoolManagerInstance</code>实例上进行管理，我们需要实现一个<code>GetBufferPoolManager</code>方法来完成这个映射，这里可以使用最简单的取模进行映射:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">BufferPoolManager *<span class="title">ParallelBufferPoolManager::GetBufferPoolManager</span><span class="params">(<span class="type">page_id_t</span> page_id)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Get BufferPoolManager responsible for handling given page id. You can use this method in your other methods.</span></span><br><span class="line">  <span class="keyword">return</span> instances_[page_id % num_instances_];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其他的接口就是调用这个方法选择对应的<code>BufferPoolManagerInstance</code>实例，调用实例上的对应接口来执行，这里就不再赘述。</p>
<p>比较特殊的是<code>NewPgImp</code>接口的实现，代码给出了注释，要求我们从一个起始位置开始进行轮询，直到某一个实例<code>NewPgImp</code>成功返回<code>page</code>指针，或者再次回到起始位置，返回null。这里我们就用到了<code>next_instance_index_</code>。<code>next_instance_index_</code>的更新也是每次+1后再与<code>num_instances_</code>取模。</p>
<p>因为这是一个并行的Buffer Pool管理器，不同的<code>page_id</code>可以分散在不同的<code>BufferPoolManagerInstance</code>上进行管理，所以只有当操作的两个页同时在一个<code>BufferPoolManagerInstance</code>中时，才会有锁竞争，<code>ParallelBufferPoolManager</code>中可以不加锁。在<code>BufferPoolManagerInstance</code>中我们也可以看到<code>AllocatePage</code>方法分配新的<code>page_id</code>时，是会有一个<code>num_instances_</code>的步长进行自增的，这里的<code>num_instances_</code>就是从<code>ParallelBufferPoolManager</code>的<code>num_instances_</code>来的，这样也保证了<code>page_id</code>的不冲突。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>经过两天的查阅资料、讨论、不断尝试，终于在Gradescope上通过了Project1的测试。</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/image-20220503002900620.png" alt="image-20220503002900620"></p>
<p>通过完成了这一个Project，把前面几讲课程的内容串起来了，不得不说对于数据库的认识又加深了，理解了Buffer Pool作为数据库管理内存的缓冲池，支撑起数据库中远大于内存容量的数据内容的工作原理。</p>
<p>在这个Project的实现中，我一是为了图方便，二是确实对应C++的内容不太熟悉，对于线程安全的保障只是简单的使用<code>std::lock_guard</code>来加解锁，这样虽然能通过评分测试，但是在实际的数据库应用中，这肯定是会带来性能隐患的，待后续来优化了。</p>
<p>其实完成之后回头看Buffer Pool的实现并没有一开始我们想象的那么复杂，尽管我们实现的只是一个简单版本的Buffer Pool，但是核心逻辑在梳理之后还是很清晰的。这其实不仅仅是因为我们实现的要求简单，还因为Project给出的代码框架有足够好的抽象和解耦，我们只需要明白每个接口的作用，梳理出Buffer Pool核心的数据流向和状态流转之后，就可以进行实现，这在系统设计层面也给我带来了不小的收获。</p>
<p>继续努力学习！</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>公开课</tag>
        <tag>CMU 15-445</tag>
      </tags>
  </entry>
  <entry>
    <title>CMU 15-445 Project 2 Hash Index</title>
    <url>/2022/05/15/CMU-15-445-Project-2-Hash-Index/</url>
    <content><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>CMU 15-445 Fall 2021的第二个project是实现一个hash table，用以支持Bustub实现哈希索引。Project 2需要实现的hash table使用<code>extendible hashing scheme</code>也就是可扩展散列的技术。<code>Extendible hashing</code>是一种动态散列的模式，当数据库增大或缩小的时候，<code>extendible hashing</code>可以通过桶的分裂和合并来适应数据库大小的变化，每次重组仅作用于一个桶，避免了对整个结构全局频繁的重组操作，降低了性能开销。</p>
<p>和Project 1类似，我们需要实现预先提供的代码中声明的API，从而完成<code>extendible hashing</code>哈希索引的实现。</p>
<p>整个Project 2页拆分成了三个任务:</p>
<ul>
<li><strong>Page Layouts</strong></li>
<li><strong>Extendible Hashing Implementation</strong></li>
<li><strong>Concurrency Control</strong></li>
</ul>
<p>第一个任务我们需要实现<code>Directory Page</code>和<code>Bucket Page</code>，<code>Directory Page</code>保存着哈希表的所有元数据，记录着<code>Bucket Page</code>相关的信息，而<code>Bucket Page</code>则保存着实际的数据，以及相关的元数据；第二个任务我们需要按照算法实现<code>extendible hashing</code>，实现包括查找、插入、删除等操作；第三个任务则需要在已实现<code>extendible hashing</code>的基础上，实现并发访问的控制。</p>
<span id="more"></span>

<h1 id="Page-Layouts"><a href="#Page-Layouts" class="headerlink" title="Page Layouts"></a>Page Layouts</h1><p>我们需要实现的hash table需要通过数据库中的buffer Pool进行访问而不是通过我们自己分配内存来实现数据存取。Buffer Pool的操作是基于页的，所以我们需要实现<code>HashTableDirectoryPage</code>和<code>HashTableBucketPage</code>两个类来定义hash table的页。</p>
<h2 id="HashTableDirectoryPage"><a href="#HashTableDirectoryPage" class="headerlink" title="HashTableDirectoryPage"></a>HashTableDirectoryPage</h2><p><code>HashTableDirectoryPage</code>类表示hash table的元数据，类中有以下属性：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** page id **/</span></span><br><span class="line"><span class="type">page_id_t</span> page_id_;</span><br><span class="line"><span class="comment">/** 日志号，后面的project会用到**/</span></span><br><span class="line"><span class="type">lsn_t</span> lsn_;</span><br><span class="line"><span class="comment">/** 全局depth,depth表示使用hash的几个bit来定位数据，后面详细介绍 **/</span></span><br><span class="line"><span class="type">uint32_t</span> global_depth_&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="comment">/** 每个bucket对应的局部depth **/</span></span><br><span class="line"><span class="type">uint8_t</span> local_depths_[DIRECTORY_ARRAY_SIZE];</span><br><span class="line"><span class="comment">/** 所有bucket的page id **/</span></span><br><span class="line"><span class="type">page_id_t</span> bucket_page_ids_[DIRECTORY_ARRAY_SIZE];</span><br></pre></td></tr></table></figure>

<p><code>HashTableDirectoryPage</code>中主要提供一些简单的方法来维护这些元数据，比如<code>IncrGlobalDepth()</code>和<code>DecrGlobalDepth()</code>等，实现都比较简单，这里不再细说，只挑选几个我认为比较有用的helper方法讲讲作用和实现：</p>
<ul>
<li><p><code>GetGlobalDepthMask</code></p>
<p>这个方法返回一个二进制表示为n位全1的uint32_t类型值，其中n等于<code>global_depth_</code>，把它与key的hash相与得到key所在的bucket的位置。实现为将1左移<code>global_depth_</code>位后减1。</p>
</li>
<li><p><code>GetSplitImageIndex(uint32_t bucket_idx)</code></p>
<p>bucket在数据已满的时候需要分裂一个新的bucket来保存数据，这个新的bucket所在的位置由这个方法来获得，其实现我们放到后面实现<code>extendible hashing</code>算法的时候来描述。</p>
</li>
<li><p><code>CanShrink()</code></p>
<p>这个方法用于判断当前hash table是否可以收缩，回收那些没有用到的bucket，其实现我们放到后面实现<code>extendible hashing</code>算法的时候来描述。</p>
</li>
</ul>
<h2 id="HashTableBucketPage"><a href="#HashTableBucketPage" class="headerlink" title="HashTableBucketPage"></a>HashTableBucketPage</h2><p><code>HashTableBucketPage</code>类是实际存储数据的地方，它有以下属性：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** 如果occupied_中第i个位为1表示array_数组中第i个元素有插入过数据 **/</span></span><br><span class="line"><span class="type">char</span> occupied_[(BUCKET_ARRAY_SIZE - <span class="number">1</span>) / <span class="number">8</span> + <span class="number">1</span>];</span><br><span class="line"><span class="comment">/** 如果readable_中第i个位为1表示array_数组中第i个元素有可读的数据 **/</span></span><br><span class="line"><span class="type">char</span> readable_[(BUCKET_ARRAY_SIZE - <span class="number">1</span>) / <span class="number">8</span> + <span class="number">1</span>];</span><br><span class="line"><span class="comment">/** 零长数组，保存key-value的值**/</span></span><br><span class="line">MappingType array_[<span class="number">0</span>];</span><br></pre></td></tr></table></figure>

<p>这里<code>occupied_</code>和<code>readable_</code>的区别需要注意下，如果在<code>array_</code>的一个位置上插入了一个key-value对，那相应的<code>occupied_</code>和<code>readable_</code>上对应位置均需要置为1，但是如果将该位置上的元素删除，只需要将<code>readable_</code>中对应位置置为0即可，<code>occupied_</code>保持为1就好。<code>occupied_</code>和<code>readable_</code>均使用1个bit来标记一个元素的状态，因此更新对应<code>array_</code>位置上元素的状态时需要通过一些位运算来找到<code>occupied_</code>和<code>readable_</code>上对应的bit。</p>
<p>Key-value对的插入和删除比较简单，插入前先遍历一遍看下待插入的key-value是否已存在，已存在返回false，否则就找到第一个<code>readable_</code>为0的位置插入即可。删除key-value对只需要遍历找到对应的位置，将该位置的<code>readable_</code>设为0即可。</p>
<p>第一个任务中我们只需要实现<code>HashTableDirectoryPage</code>中的<code>GetGlobalDepth</code> , <code>IncrGlobalDepth</code>,  <code>SetLocalDepth</code> , <code>SetBucketPageId</code>,  <code>GetBucketPageId</code>方法和<code>HashTableBucketPage</code>中的<code>Insert</code>, <code>Remove</code>, <code>IsOccupied</code>, <code>IsReadable</code>, <code>KeyAt</code>, <code>ValueAt</code>方法即可，不过在实现<code>extendible hashing</code>的过程中，我们可能会用到一些其他有用的方法，我们可以自己下来实现，比如上面讲到的<code>GetGlobalDepthMask</code>等，在下面实现<code>extendible hashing</code>算法的时候再来介绍。</p>
<p>还有一个需要注意的地方是，我们的<code>HashTableDirectoryPage</code>和<code>HashTableBucketPage</code>是从buffer Pool中获取来的，在实现中时直接使用<code>reinterpret_cast</code>从<code>Page</code>类型转换而来的，对应的就是<code>Page</code>类型头部的4k大小的<code>data_</code>，因此如非必要最好不要在<code>HashTableDirectoryPage</code>和<code>HashTableBucketPage</code>类中再添加额外的成员变量。<code>HashTableDirectoryPage</code>中因为<code>DIRECTORY_ARRAY_SIZE</code>定义为512所以4k的空间还算富裕，<code>HashTableBucketPage</code>中因为会保存大量的数据，可能会占用到4k的空间，如果再添加额外的属性可能导致访问越界，从而修改到<code>Page</code>类中的一些属性，导致问题的发生。</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/page%20layout.png" alt="page layout"></p>
<h1 id="Extendible-Hashing-Implementation"><a href="#Extendible-Hashing-Implementation" class="headerlink" title="Extendible Hashing Implementation"></a>Extendible Hashing Implementation</h1><p>我们需要按照算法描述实现<code>extendible hashing</code>算法。<code>Extendible hashing</code>是一种dynamic hash的算法，通过动态扩展的方法来解决hash冲突。<code>extendible hash table</code>分为两部分，一部分称为directory，根据数据的hash值不同将数据分散到不同的directory上，另一部分称为bucket，是真正存储数据的部分，在同一个bucket上的数据hash值相同。</p>
<p><code>Extendible hashing</code>中有一个<code>golbal depth</code>计数器，表示用数据的hash值的几位二进制位来定位该数据应该在哪个bucket之中。每个bucket上维护着自己的<code>local depth</code>，表示该bucket中的数据是用的几位hash值的二进制位来定位到这个bucket的。</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/extendible%20hash.png" alt="extendible hash"></p>
<p>如上图展示了一个<code>global depth</code>为2的<code>extendible hash table</code>，其中directory长度为4（directory长度总为<code>global depth</code>的2次幂）。总共有3个bucket，bucket中的数字表示的是bucket保存的数据的二进制hash值，根据hash值的LSB（最低有效位）来索引bucket，3个bucket的<code>local depth</code>分别为1、2、2，<code>local depth</code>总是小于等于<code>global depth</code>。</p>
<p><code>Extendible hashtable</code>的查找就是简单地根据<code>global depth</code>和hash值定位bucket，然后遍历bucket查找即可。继续以上图为例，如果我们需要在hash table中查找<code>11011001</code>这个值，根据<code>global depth</code>为2，取<code>11011001</code>后两位<code>01</code>，定位到对应的bucket，找到了对应的数据。</p>
<p><code>Extendible hashtable</code>插入数据时，也是先根据<code>global depth</code>和hash值定位需要插入的bucket，如果bucket未满，则直接将数据插入到bucket即可。如果bucket已满，则需要分裂bucket，也就是新开一个bucket用来保存数据。</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/extendible%20hash-split.png" alt="extendible hash-split"></p>
<p>如上图所示，假如我们要在这个hash table中插入hash值为<code>10100010</code>的数据，根据当前的<code>global depth</code>我们定位到<code>10</code>位置的bucket，我们可以看到<code>00</code>和<code>10</code>所指向的bucket为同一个bucket，原因我们后面分析，我们现在需要关注的是目前这个bucket中已经没有剩余的位置可以插入数据了，所以我们需要分裂bucket以便插入数据。我们先将这个bucket的<code>local depth</code>加1，然后将<code>10</code>位置指向一个新开的bucket，这个新开的bucket我们称为原来的bucket的<code>split image</code>，新bucket的<code>local depth</code>和原bucket加1后的<code>local depth</code>一样。分裂bucket完成之后我们需要将原bucket上的数据重新按<code>global depth</code>插入到相应的bucket中，然后再插入我们待插入的数据，这里<code>10100010</code>插入了<code>10</code>位置的bucket，也就是我们新开的那个bucket。</p>
<p>在分裂bucket的时候还有一种情况，即未分裂时bucket的<code>local depth</code>等于<code>global depth</code>时，我们需要扩展directory以索引更多的bucket。</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/extendible%20hash-growth.png" alt="extendible hash-growth"></p>
<p>如上图所示，当我们想要继续插入<code>11110110</code>到hash table中时，我们发现索引到的<code>10</code>位置的bucket已经满了并且<code>local depth</code>等于<code>global depth</code>，这时我们需要扩展directory的大小。<code>global depth</code>增加1，表示我们需要3个二进制位来索引bucket，directory的长度也应该扩展一倍。扩展后的directory可以索引更多的bucket，但是我们不会立即开辟新的bucket，而是将扩展部分的directory index指向已存在的bucket，<code>100</code>指向<code>000</code>所指向的bucket，<code>101</code>指向<code>001</code>所指向的bucket……以此类推，这样就完成了directory的扩展。接下来再按照分裂bucket的步骤进行插入即可。可以看到，directory发生扩展之后就会出现多个位置指向同一个bucket的情况，也就是上面我们留下的问题的答案。每次hash table扩容时，我们只需要重新处理局部的数据就可以完成扩容，而不需要重建整个hash table。</p>
<p>当删除bucket上的数据之后，如果bucket为空，我们可以合并bucket。合并bucket在某些<code>extendible hashing</code>上是没有被实现的，因为合并bucket可能在某些场景下产生性能抖动。当bucket为空，bucket与其<code>split image</code>的<code>local depth</code>相等且大于0时，bucket才可以与其<code>split image</code>合并。合并bucket就是将原本指向bucket的索引指向其<code>split image</code>，然后<code>local depth</code>减1，这样空bucket就不再存在于hash table之中。当hash table中合并的bucket越来越多时，很多不同的位置都是指向的同一个bucket，这时还可以进行directory的收缩，当且仅当所有bucket的<code>local depth</code>都小于<code>global depth</code>时，directory才可以进行收缩，收缩directory需要将<code>global depth</code>减1。</p>
<p>以上就是<code>extendible hashing</code>算法的描述，包括了查找、插入、删除、bucket的分裂和合并，directory的扩展和收缩等操作。在实现project时，如第一个任务所述，我们的directory和bucket是基于buffer pool来管理的，所以我们会用到<code>BufferPoolManagerInstance</code>类提供的API。当我们需要新开辟directory或bucket时，我们需要调用<code>NewPage</code>来申请一个新的页，并将返回的<code>Page</code>对象转换为<code>HashTableDirectoryPage</code>或<code>HashTableBucketPage</code>对象，使用一个已申请的页时需要调用<code>FetchPage</code>，当页使用完毕时调用<code>UnpinPage</code>取消页的固定，并根据页的变更状态正确设置<code>is_dirty</code> flag以保证写入的数据能够被安全地写入磁盘。</p>
<p>在实现这一任务的时候，我们可以不用考虑多线程并发时线程安全问题的处理，只需要实现单线程下的行为正确的<code>extendibel hashing</code>算法即可。</p>
<h1 id="Concurrency-Control"><a href="#Concurrency-Control" class="headerlink" title="Concurrency Control"></a>Concurrency Control</h1><p>在这一任务中我们需要实现并发安全的<code>extendibel hashing</code>算法。在实现上一任务的基础之上，我们需要使用锁来保护并发访问时的hash table。</p>
<p>代码中提供了两种粒度的锁，一种是定义于<code>ExtendibleHashTable</code>类中的<code>table_latch_</code>，锁的粒度为整个hash table实例，一种是<code>Page</code>类中的<code>rwlatch_</code>，锁的粒度为对应的<code>Page</code>对象，看代码的实现我们可以看到它们都是<code>ReaderWriterLatch</code>封装的读写锁，锁实现均为不可重入锁。</p>
<p>我们只有在需要对directory或bucket进行写入操作时才去获取对应粒度的写锁，其他时候一律只获取读锁。因为<code>global dept</code>、<code>local depth</code>、bucket page id等元数据都是在<code>HashTableDirectoryPage</code>类中维护的，因此我们可以等到存在数据操作时才对bucket进行加锁。还有一个点需要注意的是，当后续操作可能需要写锁时，就在操作最开始获取写锁，不要先获取读锁然后当需要写锁时才去获取写锁，因为代码中的锁是不可重入锁，获取另一个锁之前需要先释放持有的锁，这期间就有可能发生竞争，反而会产生并发问题，性能也不会得到优化。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>第二个project的难度相比第一个要大一点，主要是PPT中描述的<code>extendibel hashing</code>有些抽象导致理解多花费了些时间，选择采用LSB来定位bucket之后，实现的难度和理解起来其实会比PPT中使用MSB要简单些。</p>
<p><img src="https://images-1253386616.cos.ap-guangzhou.myqcloud.com/image-1654531228246.png" alt="image-1654531228246"></p>
<p>本次project实现的<code>extendibel hashing</code>可以作为实现数据库hash索引的基础。课程中还提到一种数据结构 - B+树，它也是实现数据库索引的一种优秀的数据结构，在2020学年的project 2是实现的B+树，我也准备尝试一下B+树的实现，以及B+树的并发安全访问实现。</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>公开课</tag>
        <tag>CMU 15-445</tag>
      </tags>
  </entry>
</search>
